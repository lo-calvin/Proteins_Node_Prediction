{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import scatter\n",
    "# Temporarily set weights_only to False when loading\n",
    "original_torch_load = torch.load\n",
    "\n",
    "def torch_load_with_weights_only_false(*args, **kwargs):\n",
    "    kwargs['weights_only'] = False\n",
    "    return original_torch_load(*args, **kwargs)\n",
    "\n",
    "torch.load = torch_load_with_weights_only_false\n",
    "\n",
    "# Load the dataset\n",
    "dataset = NodePropPredDataset(name=\"ogbn-proteins\", root=\"dataset/\")\n",
    "\n",
    "# Restore torch.load to its original function\n",
    "torch.load = original_torch_load\n",
    "\n",
    "split_idx = dataset.get_idx_split()  # which ones are training nodes, val, etc\n",
    "\n",
    "print(\"Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph_data: \n",
    "- edge_index: COO format (coordinate format) \n",
    "    - shape: (2, 79122504)\n",
    "    - 79122504 edges\n",
    "    - 0: source node, 1: destination node\n",
    "- edge_feat:\n",
    "    - shape: (79122504, 8)\n",
    "    - 8 dimensional feature vector for each edge\n",
    "- node_feat:\n",
    "    - Node features: none for this dataset\n",
    "- node_species:\n",
    "    - shape: (132534, 1)\n",
    "    - Species identifiers for each node\n",
    "- num_nodes:\n",
    "    - 132534 nodes\n",
    "\n",
    "node_labels:\n",
    "- shape: (132534, 112)\n",
    "- 112 types of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import scatter\n",
    "from torch_geometric.loader import RandomNodeLoader\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Access the single graph\n",
    "graph_data, node_labels = dataset[0]\n",
    "\n",
    "# Split the nodes based on the split indices\n",
    "split_idx = dataset.get_idx_split()  # which ones are training, val, test nodes\n",
    "train_idx = split_idx[\"train\"]\n",
    "valid_idx = split_idx[\"valid\"]\n",
    "test_idx = split_idx[\"test\"]\n",
    "\n",
    "# Create masks\n",
    "train_mask = torch.zeros(graph_data['num_nodes'], dtype=torch.bool)\n",
    "valid_mask = torch.zeros(graph_data['num_nodes'], dtype=torch.bool)\n",
    "test_mask = torch.zeros(graph_data['num_nodes'], dtype=torch.bool)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "valid_mask[valid_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "# Convert edge features and edge index to tensors\n",
    "graph_data['edge_feat'] = torch.tensor(graph_data['edge_feat'], dtype=torch.float32)\n",
    "graph_data['edge_index'] = torch.tensor(graph_data['edge_index'], dtype=torch.long)\n",
    "\n",
    "# initialize node features by aggregating edge features\n",
    "graph_data['node_feat'] = scatter(graph_data['edge_feat'], \n",
    "                                  graph_data['edge_index'][1],\n",
    "                                  dim=0,\n",
    "                                  dim_size=graph_data['num_nodes'],\n",
    "                                  reduce='sum')\n",
    "\n",
    "# load graph into PyG data object\n",
    "data = Data(\n",
    "    edge_index=graph_data['edge_index'],\n",
    "    edge_attr=graph_data['edge_feat'],\n",
    "    num_nodes=graph_data['num_nodes'],\n",
    "    y=node_labels,\n",
    "    x=graph_data['node_feat'],\n",
    "    train_mask=train_mask,\n",
    "    valid_mask=valid_mask,\n",
    "    test_mask=test_mask\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = RandomNodeLoader(data, num_parts=40, shuffle=True,\n",
    "                                num_workers=5)\n",
    "test_loader = RandomNodeLoader(data, num_parts=5, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch\n",
    "from ogb.nodeproppred import Evaluator, PygNodePropPredDataset\n",
    "from torch.nn import LayerNorm, Linear, ReLU\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import RandomNodeLoader\n",
    "from torch_geometric.nn import DeepGCNLayer, GENConv\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "class DeeperGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, edge_in_channels, hidden_channels, num_classes, num_layers):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.node_encoder = Linear(in_channels, hidden_channels)    \n",
    "        self.edge_encoder = Linear(edge_in_channels, hidden_channels)\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(0, num_layers):\n",
    "            # num_layers is layers in MLP\n",
    "            conv = GENConv(hidden_channels, hidden_channels, aggr='softmax',\n",
    "                           t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "            norm = LayerNorm(hidden_channels, elementwise_affine=True)\n",
    "            act = ReLU(inplace=True)\n",
    "            layer = DeepGCNLayer(conv, norm, act, block='res+', dropout=0.1)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_feat):\n",
    "        # encode node and edge features to higher dimensional space\n",
    "        h = self.node_encoder(x)\n",
    "        edge_embeddings = self.edge_encoder(edge_feat)\n",
    "\n",
    "        # pass through layers\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, edge_index, edge_embeddings)\n",
    "  \n",
    "        # drop out and classifier\n",
    "        h = F.dropout(h, p=0.1, training=self.training)\n",
    "        h = self.lin(h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "\n",
    "def train(model, optimizer, criterion, train_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.train()\n",
    "    total_loss = total_examples = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * int(data.train_mask.sum())\n",
    "        total_examples += int(data.train_mask.sum())\n",
    "\n",
    "    return total_loss / total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DeeperGCN(in_channels=8, edge_in_channels=8, hidden_channels=64, num_classes=112, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "evaluator = Evaluator('ogbn-proteins')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 20255361024 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, optimizer, criterion, train_loader)\u001b[39m\n\u001b[32m     52\u001b[39m optimizer.zero_grad()  \u001b[38;5;66;03m# Clear gradients.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Forward pass: use only the training nodes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Mask the output and labels to only include training nodes\u001b[39;00m\n\u001b[32m     58\u001b[39m train_out = out[data.train_mask]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mDeeperGCN.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_feat)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_feat):\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# encode node and edge features to higher dimensional space\u001b[39;00m\n\u001b[32m     35\u001b[39m     h = \u001b[38;5;28mself\u001b[39m.node_encoder(x)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     edge_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43medge_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_feat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;66;03m# pass through layers\u001b[39;00m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at alloc_cpu.cpp:115] data. DefaultCPUAllocator: not enough memory: you tried to allocate 20255361024 bytes."
     ]
    }
   ],
   "source": [
    "loss = train(model, optimizer, criterion, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataLoader found invalid type: '<class 'numpy.int64'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m y_true = {\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m: []}\n\u001b[32m      2\u001b[39m y_pred = {\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m: [], \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m: []}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CLO\\OneDrive - Stryker\\School\\CS6140\\Final_Project\\.venv\\Lib\\site-packages\\torch_geometric\\loader\\dataloader.py:49\u001b[39m, in \u001b[36mCollater.__call__\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*batch)]\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader found invalid type: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(elem)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: DataLoader found invalid type: '<class 'numpy.int64'>'"
     ]
    }
   ],
   "source": [
    "y_true = {'train': [], 'valid': [], 'test': []}\n",
    "y_pred = {'train': [], 'valid': [], 'test': []}\n",
    "\n",
    "for data in test_loader:\n",
    "    out = model(data.x, data.edge_index, data.edge_attr)\n",
    "\n",
    "    for split in y_true.keys():\n",
    "        mask = data[f'{split}_mask']\n",
    "        y_true[split].append(data.y[mask].cpu())\n",
    "        y_pred[split].append(out[mask].cpu())\n",
    "\n",
    "train_rocauc = evaluator.eval({\n",
    "        'y_true': torch.cat(y_true['train'], dim=0),\n",
    "        'y_pred': torch.cat(y_pred['train'], dim=0),\n",
    "    })['rocauc']\n",
    "\n",
    "valid_rocauc = evaluator.eval({\n",
    "    'y_true': torch.cat(y_true['valid'], dim=0),\n",
    "    'y_pred': torch.cat(y_pred['valid'], dim=0),\n",
    "})['rocauc']\n",
    "\n",
    "test_rocauc = evaluator.eval({\n",
    "    'y_true': torch.cat(y_true['test'], dim=0),\n",
    "    'y_pred': torch.cat(y_pred['test'], dim=0),\n",
    "})['rocauc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_graph(G, color):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
    "                     node_color=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "graph_data, node_labels = dataset[0]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "edge_index = torch.tensor(graph_data['edge_index'], dtype=torch.long)\n",
    "edge_attr = torch.tensor(graph_data['edge_feat'], dtype=torch.float)\n",
    "node_species = torch.tensor(graph_data['node_species'], dtype=torch.long)\n",
    "node_labels = torch.tensor(node_labels, dtype=torch.float)\n",
    "\n",
    "# Create PyG Data object\n",
    "pyg_data = Data(edge_index=edge_index, edge_attr=edge_attr, y=node_labels, num_nodes=graph_data['num_nodes'])\n",
    "\n",
    "# # data = dataset[0]\n",
    "# G = to_networkx(pyg_data, to_undirected=True)\n",
    "# visualize_graph(G, color=pyg_data.y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
